{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "execution": {
          "iopub.execute_input": "2024-04-07T20:10:51.040331Z",
          "iopub.status.busy": "2024-04-07T20:10:51.039701Z",
          "iopub.status.idle": "2024-04-07T20:11:05.525029Z",
          "shell.execute_reply": "2024-04-07T20:11:05.523746Z",
          "shell.execute_reply.started": "2024-04-07T20:10:51.040292Z"
        },
        "id": "jLfBjLDcoLKR",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "!pip install -q transformers\\\n",
        "datasets\\\n",
        "sentencepiece\\\n",
        "pytorch-lightning\\\n",
        "wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-07T20:11:05.527183Z",
          "iopub.status.busy": "2024-04-07T20:11:05.526874Z",
          "iopub.status.idle": "2024-04-07T20:11:05.821629Z",
          "shell.execute_reply": "2024-04-07T20:11:05.820665Z",
          "shell.execute_reply.started": "2024-04-07T20:11:05.527155Z"
        },
        "id": "S_iIjyeBoLKS",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import notebook_login\n",
        "\n",
        "notebook_login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-07T20:11:12.745715Z",
          "iopub.status.busy": "2024-04-07T20:11:12.744843Z",
          "iopub.status.idle": "2024-04-07T20:11:14.607698Z",
          "shell.execute_reply": "2024-04-07T20:11:14.606708Z",
          "shell.execute_reply.started": "2024-04-07T20:11:12.745677Z"
        },
        "id": "gVpch119oLKT",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "!huggingface-cli whoami"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-07T20:11:36.71668Z",
          "iopub.status.busy": "2024-04-07T20:11:36.715832Z",
          "iopub.status.idle": "2024-04-07T20:14:11.026388Z",
          "shell.execute_reply": "2024-04-07T20:14:11.024982Z",
          "shell.execute_reply.started": "2024-04-07T20:11:36.716642Z"
        },
        "id": "BxNDYZJtoLKU",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\"Henge-navuuu/Multiple_financial_forms\", use_auth_token=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-07T20:14:11.028737Z",
          "iopub.status.busy": "2024-04-07T20:14:11.028284Z",
          "iopub.status.idle": "2024-04-07T20:14:11.035371Z",
          "shell.execute_reply": "2024-04-07T20:14:11.034498Z",
          "shell.execute_reply.started": "2024-04-07T20:14:11.02871Z"
        },
        "id": "ni_YN0L8oLKV",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-07T20:14:11.036715Z",
          "iopub.status.busy": "2024-04-07T20:14:11.03647Z",
          "iopub.status.idle": "2024-04-07T20:14:14.345648Z",
          "shell.execute_reply": "2024-04-07T20:14:14.344539Z",
          "shell.execute_reply.started": "2024-04-07T20:14:11.03669Z"
        },
        "id": "YfKd7aWUoLKX",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "example = dataset['train'][0]\n",
        "image = example['image']\n",
        "# let's make the image a bit smaller when visualizing\n",
        "width, height = image.size\n",
        "display(image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-07T20:14:14.348476Z",
          "iopub.status.busy": "2024-04-07T20:14:14.348183Z",
          "iopub.status.idle": "2024-04-07T20:14:14.355557Z",
          "shell.execute_reply": "2024-04-07T20:14:14.354602Z",
          "shell.execute_reply.started": "2024-04-07T20:14:14.348451Z"
        },
        "id": "lnQQHgFtoLKX",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "print(width, height)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-07T20:14:14.357353Z",
          "iopub.status.busy": "2024-04-07T20:14:14.3569Z",
          "iopub.status.idle": "2024-04-07T20:14:16.292943Z",
          "shell.execute_reply": "2024-04-07T20:14:16.291738Z",
          "shell.execute_reply.started": "2024-04-07T20:14:14.357309Z"
        },
        "id": "6EOTg5ZMoLKY",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "ground_truth = example['ground_truth']\n",
        "print(ground_truth)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-07T20:14:38.621979Z",
          "iopub.status.busy": "2024-04-07T20:14:38.621145Z",
          "iopub.status.idle": "2024-04-07T20:14:38.62923Z",
          "shell.execute_reply": "2024-04-07T20:14:38.628207Z",
          "shell.execute_reply.started": "2024-04-07T20:14:38.621951Z"
        },
        "id": "SfSchS1doLKY",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "from ast import literal_eval\n",
        "\n",
        "literal_eval(ground_truth)['gt_parse']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-07T20:15:54.270154Z",
          "iopub.status.busy": "2024-04-07T20:15:54.269753Z",
          "iopub.status.idle": "2024-04-07T20:16:01.463928Z",
          "shell.execute_reply": "2024-04-07T20:16:01.462907Z",
          "shell.execute_reply.started": "2024-04-07T20:15:54.270126Z"
        },
        "id": "OLPMmFgYoLKZ",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "from transformers import VisionEncoderDecoderConfig\n",
        "\n",
        "# update image_size of the encoder\n",
        "image_size = [1864, 1440]\n",
        "max_length = 1000\n",
        "\n",
        "config = VisionEncoderDecoderConfig.from_pretrained(\"naver-clova-ix/donut-base\")\n",
        "config.encoder.image_size = image_size # (height, width)\n",
        "# update max_length of the decoder (for generation)\n",
        "config.decoder.max_length = max_length\n",
        "# TODO we should actually update max_position_embeddings and interpolate the pre-trained ones:\n",
        "# https://github.com/clovaai/donut/blob/0acc65a85d140852b8d9928565f0f6b2d98dc088/donut/model.py#L602"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-07T20:16:01.466108Z",
          "iopub.status.busy": "2024-04-07T20:16:01.465538Z",
          "iopub.status.idle": "2024-04-07T20:16:27.325279Z",
          "shell.execute_reply": "2024-04-07T20:16:27.323882Z",
          "shell.execute_reply.started": "2024-04-07T20:16:01.466078Z"
        },
        "id": "nSQHe2vzoLKa",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "from transformers import DonutProcessor, VisionEncoderDecoderModel\n",
        "\n",
        "processor = DonutProcessor.from_pretrained(\"naver-clova-ix/donut-base\")\n",
        "model = VisionEncoderDecoderModel.from_pretrained(\"naver-clova-ix/donut-base\", config=config)\n",
        "# model.to(torch.device(1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-07T20:16:52.064785Z",
          "iopub.status.busy": "2024-04-07T20:16:52.063673Z",
          "iopub.status.idle": "2024-04-07T20:16:52.091529Z",
          "shell.execute_reply": "2024-04-07T20:16:52.090654Z",
          "shell.execute_reply.started": "2024-04-07T20:16:52.064733Z"
        },
        "id": "K-7g2p03oLKb",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import random\n",
        "from typing import Any, List, Tuple\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "added_tokens = []\n",
        "\n",
        "class DonutDataset(Dataset):\n",
        "    \"\"\"\n",
        "    PyTorch Dataset for Donut. This class takes a HuggingFace Dataset as input.\n",
        "\n",
        "    Each row, consists of image path(png/jpg/jpeg) and gt data (json/jsonl/txt),\n",
        "    and it will be converted into pixel_values (vectorized image) and labels (input_ids of the tokenized string).\n",
        "\n",
        "    Args:\n",
        "        dataset_name_or_path: name of dataset (available at huggingface.co/datasets) or the path containing image files and metadata.jsonl\n",
        "        max_length: the max number of tokens for the target sequences\n",
        "        split: whether to load \"train\", \"validation\" or \"test\" split\n",
        "        ignore_id: ignore_index for torch.nn.CrossEntropyLoss\n",
        "        task_start_token: the special token to be fed to the decoder to conduct the target task\n",
        "        prompt_end_token: the special token at the end of the sequences\n",
        "        sort_json_key: whether or not to sort the JSON keys\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        dataset_name_or_path: str,\n",
        "        max_length: int,\n",
        "        split: str = \"train\",\n",
        "        ignore_id: int = -100,\n",
        "        task_start_token: str = \"<s>\",\n",
        "        prompt_end_token: str = None,\n",
        "        sort_json_key: bool = True,\n",
        "#         samples = 100\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        self.max_length = max_length\n",
        "        self.split = split\n",
        "        self.ignore_id = ignore_id\n",
        "        self.task_start_token = task_start_token\n",
        "        self.prompt_end_token = prompt_end_token if prompt_end_token else task_start_token\n",
        "        self.sort_json_key = sort_json_key\n",
        "#         self.samples = samples\n",
        "\n",
        "        self.dataset = load_dataset(dataset_name_or_path, split=self.split, use_auth_token=True)\n",
        "        self.dataset_length = len(self.dataset)\n",
        "\n",
        "        self.gt_token_sequences = []\n",
        "        for sample in self.dataset:\n",
        "            ground_truth = json.loads(sample[\"ground_truth\"])\n",
        "            if \"gt_parses\" in ground_truth:  # when multiple ground truths are available, e.g., docvqa\n",
        "                assert isinstance(ground_truth[\"gt_parses\"], list)\n",
        "                gt_jsons = ground_truth[\"gt_parses\"]\n",
        "            else:\n",
        "                assert \"gt_parse\" in ground_truth and isinstance(ground_truth[\"gt_parse\"], dict)\n",
        "                gt_jsons = [ground_truth[\"gt_parse\"]]\n",
        "\n",
        "            self.gt_token_sequences.append(\n",
        "                [\n",
        "                    self.json2token(\n",
        "                        gt_json,\n",
        "                        update_special_tokens_for_json_key=self.split == \"train\",\n",
        "                        sort_json_key=self.sort_json_key,\n",
        "                    )\n",
        "                    + processor.tokenizer.eos_token\n",
        "                    for gt_json in gt_jsons  # load json from list of json\n",
        "                ]\n",
        "            )\n",
        "\n",
        "        self.add_tokens([self.task_start_token, self.prompt_end_token])\n",
        "        self.prompt_end_token_id = processor.tokenizer.convert_tokens_to_ids(self.prompt_end_token)\n",
        "\n",
        "    def json2token(self, obj: Any, update_special_tokens_for_json_key: bool = True, sort_json_key: bool = True):\n",
        "        \"\"\"\n",
        "        Convert an ordered JSON object into a token sequence\n",
        "        \"\"\"\n",
        "        if type(obj) == dict:\n",
        "            if len(obj) == 1 and \"text_sequence\" in obj:\n",
        "                return obj[\"text_sequence\"]\n",
        "            else:\n",
        "                output = \"\"\n",
        "                if sort_json_key:\n",
        "                    keys = sorted(obj.keys(), reverse=True)\n",
        "                else:\n",
        "                    keys = obj.keys()\n",
        "                for k in keys:\n",
        "                    if update_special_tokens_for_json_key:\n",
        "                        self.add_tokens([fr\"<s_{k}>\", fr\"</s_{k}>\"])\n",
        "                    output += (\n",
        "                        fr\"<s_{k}>\"\n",
        "                        + self.json2token(obj[k], update_special_tokens_for_json_key, sort_json_key)\n",
        "                        + fr\"</s_{k}>\"\n",
        "                    )\n",
        "                return output\n",
        "        elif type(obj) == list:\n",
        "            return r\"<sep/>\".join(\n",
        "                [self.json2token(item, update_special_tokens_for_json_key, sort_json_key) for item in obj]\n",
        "            )\n",
        "        else:\n",
        "            obj = str(obj)\n",
        "            if f\"<{obj}/>\" in added_tokens:\n",
        "                obj = f\"<{obj}/>\"  # for categorical special tokens\n",
        "            return obj\n",
        "\n",
        "    def add_tokens(self, list_of_tokens: List[str]):\n",
        "        \"\"\"\n",
        "        Add special tokens to tokenizer and resize the token embeddings of the decoder\n",
        "        \"\"\"\n",
        "        newly_added_num = processor.tokenizer.add_tokens(list_of_tokens)\n",
        "        if newly_added_num > 0:\n",
        "            model.decoder.resize_token_embeddings(len(processor.tokenizer))\n",
        "            added_tokens.extend(list_of_tokens)\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return self.dataset_length\n",
        "\n",
        "    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
        "        \"\"\"\n",
        "        Load image from image_path of given dataset_path and convert into input_tensor and labels\n",
        "        Convert gt data into input_ids (tokenized string)\n",
        "        Returns:\n",
        "            input_tensor : preprocessed image\n",
        "            input_ids : tokenized gt_data\n",
        "            labels : masked labels (model doesn't need to predict prompt and pad token)\n",
        "        \"\"\"\n",
        "        sample = self.dataset[idx]\n",
        "\n",
        "        # inputs\n",
        "        pixel_values = processor(sample[\"image\"], random_padding=self.split == \"train\", return_tensors=\"pt\").pixel_values\n",
        "        pixel_values = pixel_values.squeeze()\n",
        "\n",
        "        # targets\n",
        "        target_sequence = random.choice(self.gt_token_sequences[idx])  # can be more than one, e.g., DocVQA Task 1\n",
        "        input_ids = processor.tokenizer(\n",
        "            target_sequence,\n",
        "            add_special_tokens=False,\n",
        "            max_length=self.max_length,\n",
        "            padding=\"max_length\",\n",
        "            truncation=True,\n",
        "            return_tensors=\"pt\",\n",
        "        )[\"input_ids\"].squeeze(0)\n",
        "\n",
        "        labels = input_ids.clone()\n",
        "        labels[labels == processor.tokenizer.pad_token_id] = self.ignore_id  # model doesn't need to predict pad token\n",
        "        return pixel_values, labels, target_sequence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-07T20:17:19.480369Z",
          "iopub.status.busy": "2024-04-07T20:17:19.479706Z",
          "iopub.status.idle": "2024-04-07T20:22:30.076486Z",
          "shell.execute_reply": "2024-04-07T20:22:30.075592Z",
          "shell.execute_reply.started": "2024-04-07T20:17:19.48034Z"
        },
        "id": "5YKr8rxMoLKb",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "processor.image_processor.size = image_size[::-1] # (width, height)\n",
        "processor.image_processor.do_align_long_axis = False\n",
        "\n",
        "train_dataset = DonutDataset(\"Henge-navuuu/Multiple_financial_forms\", max_length=max_length,\n",
        "                             split=\"train\",\n",
        "                             sort_json_key=True,\n",
        "#                              samples = 800\n",
        "                             )\n",
        "\n",
        "val_dataset = DonutDataset(\"Henge-navuuu/Multiple_financial_forms\", max_length=max_length,\n",
        "                             split=\"validation\",\n",
        "                             sort_json_key=True,\n",
        "#                              samples = 100\n",
        "                             )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-07T20:22:36.057684Z",
          "iopub.status.busy": "2024-04-07T20:22:36.05676Z",
          "iopub.status.idle": "2024-04-07T20:22:36.063146Z",
          "shell.execute_reply": "2024-04-07T20:22:36.061976Z",
          "shell.execute_reply.started": "2024-04-07T20:22:36.057648Z"
        },
        "id": "KY2vi-0yoLKc",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "print(len(train_dataset))\n",
        "print(len(val_dataset))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-07T20:22:38.850026Z",
          "iopub.status.busy": "2024-04-07T20:22:38.849663Z",
          "iopub.status.idle": "2024-04-07T20:22:38.866427Z",
          "shell.execute_reply": "2024-04-07T20:22:38.865314Z",
          "shell.execute_reply.started": "2024-04-07T20:22:38.849997Z"
        },
        "id": "0i6Ggiy7oLKc",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# the vocab size attribute stays constants (might be a bit unintuitive - but doesn't include special tokens)\n",
        "print(\"Original number of tokens:\", processor.tokenizer.vocab_size)\n",
        "print(\"Number of tokens after adding special tokens:\", len(processor.tokenizer))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-07T20:22:43.466001Z",
          "iopub.status.busy": "2024-04-07T20:22:43.465558Z",
          "iopub.status.idle": "2024-04-07T20:22:43.705408Z",
          "shell.execute_reply": "2024-04-07T20:22:43.704435Z",
          "shell.execute_reply.started": "2024-04-07T20:22:43.465954Z"
        },
        "id": "rkT-uGqIoLKc",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "print(processor.decode([57560]))\n",
        "pixel_values, labels, target_sequence = train_dataset[0]\n",
        "print(pixel_values.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-07T20:22:47.126078Z",
          "iopub.status.busy": "2024-04-07T20:22:47.125103Z",
          "iopub.status.idle": "2024-04-07T20:22:47.133013Z",
          "shell.execute_reply": "2024-04-07T20:22:47.131953Z",
          "shell.execute_reply.started": "2024-04-07T20:22:47.126041Z"
        },
        "id": "h9k28adgoLKc",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# let's print the labels (the first 30 token ID's)\n",
        "for id in labels.tolist()[:30]:\n",
        "  if id != -100:\n",
        "    print(processor.decode([id]))\n",
        "  else:\n",
        "    print(id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-07T20:22:49.731071Z",
          "iopub.status.busy": "2024-04-07T20:22:49.730661Z",
          "iopub.status.idle": "2024-04-07T20:22:49.735977Z",
          "shell.execute_reply": "2024-04-07T20:22:49.735015Z",
          "shell.execute_reply.started": "2024-04-07T20:22:49.731041Z"
        },
        "id": "0YQl82tHoLKd",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# let's check the corresponding target sequence, as a string\n",
        "print(target_sequence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-07T20:23:00.490985Z",
          "iopub.status.busy": "2024-04-07T20:23:00.490612Z",
          "iopub.status.idle": "2024-04-07T20:23:00.495906Z",
          "shell.execute_reply": "2024-04-07T20:23:00.494816Z",
          "shell.execute_reply.started": "2024-04-07T20:23:00.490958Z"
        },
        "id": "RFZ1TVLBoLKd",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "model.config.pad_token_id = processor.tokenizer.pad_token_id\n",
        "model.config.decoder_start_token_id = processor.tokenizer.convert_tokens_to_ids(['<s>'])[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-07T20:23:02.880792Z",
          "iopub.status.busy": "2024-04-07T20:23:02.879789Z",
          "iopub.status.idle": "2024-04-07T20:23:02.88651Z",
          "shell.execute_reply": "2024-04-07T20:23:02.885478Z",
          "shell.execute_reply.started": "2024-04-07T20:23:02.880735Z"
        },
        "id": "FX42eKxSoLKd",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# sanity check\n",
        "print(\"Pad token ID:\", processor.decode([model.config.pad_token_id]))\n",
        "print(\"Decoder start token ID:\", processor.decode([model.config.decoder_start_token_id]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-07T20:23:09.809971Z",
          "iopub.status.busy": "2024-04-07T20:23:09.809608Z",
          "iopub.status.idle": "2024-04-07T20:23:09.815783Z",
          "shell.execute_reply": "2024-04-07T20:23:09.814781Z",
          "shell.execute_reply.started": "2024-04-07T20:23:09.809945Z"
        },
        "id": "CiMtlZ5WoLKe",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# feel free to increase the batch size if you have a lot of memory\n",
        "# I'm fine-tuning on Colab and given the large image size, batch size > 1 is not feasible\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=1, shuffle=True, num_workers=4)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=1, shuffle=False, num_workers=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-07T20:23:12.525467Z",
          "iopub.status.busy": "2024-04-07T20:23:12.524615Z",
          "iopub.status.idle": "2024-04-07T20:23:13.434875Z",
          "shell.execute_reply": "2024-04-07T20:23:13.433566Z",
          "shell.execute_reply.started": "2024-04-07T20:23:12.525433Z"
        },
        "id": "iLzVktN-oLKe",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "batch = next(iter(train_dataloader))\n",
        "pixel_values, labels, target_sequences = batch\n",
        "print(pixel_values.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-07T20:23:15.946084Z",
          "iopub.status.busy": "2024-04-07T20:23:15.945192Z",
          "iopub.status.idle": "2024-04-07T20:23:15.953182Z",
          "shell.execute_reply": "2024-04-07T20:23:15.952236Z",
          "shell.execute_reply.started": "2024-04-07T20:23:15.94604Z"
        },
        "id": "2h3CUz9xoLKe",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "for id in labels.squeeze().tolist()[:30]:\n",
        "  if id != -100:\n",
        "    print(processor.decode([id]))\n",
        "  else:\n",
        "    print(id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-07T20:23:36.122546Z",
          "iopub.status.busy": "2024-04-07T20:23:36.121975Z",
          "iopub.status.idle": "2024-04-07T20:23:40.064187Z",
          "shell.execute_reply": "2024-04-07T20:23:40.063345Z",
          "shell.execute_reply.started": "2024-04-07T20:23:36.122494Z"
        },
        "id": "Su5Tuy-coLKf",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "import re\n",
        "from nltk import edit_distance\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch.optim.lr_scheduler import LambdaLR\n",
        "\n",
        "import pytorch_lightning as pl\n",
        "from pytorch_lightning.utilities import rank_zero_only\n",
        "\n",
        "\n",
        "class DonutModelPLModule(pl.LightningModule):\n",
        "    def __init__(self, config, processor, model):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "        self.processor = processor\n",
        "        self.model = model\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        pixel_values, labels, _ = batch\n",
        "\n",
        "        outputs = self.model(pixel_values, labels=labels)\n",
        "        loss = outputs.loss\n",
        "        self.log(\"train_loss\", loss)\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx, dataset_idx=0):\n",
        "        pixel_values, labels, answers = batch\n",
        "        batch_size = pixel_values.shape[0]\n",
        "        # we feed the prompt to the model\n",
        "        decoder_input_ids = torch.full((batch_size, 1), self.model.config.decoder_start_token_id, device=self.device)\n",
        "\n",
        "        outputs = self.model.generate(pixel_values,\n",
        "                                   decoder_input_ids=decoder_input_ids,\n",
        "                                   max_length=max_length,\n",
        "                                   early_stopping=True,\n",
        "                                   pad_token_id=self.processor.tokenizer.pad_token_id,\n",
        "                                   eos_token_id=self.processor.tokenizer.eos_token_id,\n",
        "                                   use_cache=True,\n",
        "                                   num_beams=1,\n",
        "                                   bad_words_ids=[[self.processor.tokenizer.unk_token_id]],\n",
        "                                   return_dict_in_generate=True,)\n",
        "\n",
        "        predictions = []\n",
        "        for seq in self.processor.tokenizer.batch_decode(outputs.sequences):\n",
        "            seq = seq.replace(self.processor.tokenizer.eos_token, \"\").replace(self.processor.tokenizer.pad_token, \"\")\n",
        "            seq = re.sub(r\"<.*?>\", \"\", seq, count=1).strip()  # remove first task start token\n",
        "            predictions.append(seq)\n",
        "\n",
        "        scores = []\n",
        "        for pred, answer in zip(predictions, answers):\n",
        "            pred = re.sub(r\"(?:(?<=>) | (?=</s_))\", \"\", pred)\n",
        "            # NOT NEEDED ANYMORE\n",
        "            # answer = re.sub(r\"<.*?>\", \"\", answer, count=1)\n",
        "            answer = answer.replace(self.processor.tokenizer.eos_token, \"\")\n",
        "            scores.append(edit_distance(pred, answer) / max(len(pred), len(answer)))\n",
        "\n",
        "            if self.config.get(\"verbose\", False) and len(scores) == 1:\n",
        "#                 print(f\"Prediction: {pred}\")\n",
        "#                 print(f\"    Answer: {answer}\")\n",
        "                print(f\" Normed ED: {scores[0]}\")\n",
        "\n",
        "        self.log(\"val_edit_distance\", np.mean(scores))\n",
        "\n",
        "        return scores\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        # you could also add a learning rate scheduler if you want\n",
        "        optimizer = torch.optim.Adam(self.parameters(), lr=self.config.get(\"lr\"))\n",
        "\n",
        "        return optimizer\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        return train_dataloader\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        return val_dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-07T20:23:40.067264Z",
          "iopub.status.busy": "2024-04-07T20:23:40.065777Z",
          "iopub.status.idle": "2024-04-07T20:23:40.072049Z",
          "shell.execute_reply": "2024-04-07T20:23:40.071027Z",
          "shell.execute_reply.started": "2024-04-07T20:23:40.067228Z"
        },
        "id": "sBfpfhteoLKf",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.mkdir('/kaggle/working/results')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-07T20:24:00.670275Z",
          "iopub.status.busy": "2024-04-07T20:24:00.669479Z",
          "iopub.status.idle": "2024-04-07T20:24:00.676547Z",
          "shell.execute_reply": "2024-04-07T20:24:00.675483Z",
          "shell.execute_reply.started": "2024-04-07T20:24:00.67024Z"
        },
        "id": "hBIiXpJtoLKf",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "config = {\"max_epochs\":3,\n",
        "          \"val_check_interval\":0.5, # how many times we want to validate during an epoch\n",
        "          \"check_val_every_n_epoch\":1,\n",
        "          \"gradient_clip_val\":1.0,\n",
        "          \"num_training_samples_per_epoch\": 3000,\n",
        "          \"lr\":3e-5,\n",
        "          \"train_batch_sizes\": [10],\n",
        "          \"val_batch_sizes\": [20],\n",
        "          # \"seed\":2022,\n",
        "          \"num_nodes\": 1,\n",
        "          \"warmup_steps\": 200, # 800/8*30/10, 10%\n",
        "          \"result_path\": \"/kaggle/working/results\",\n",
        "          \"verbose\": True,\n",
        "          }\n",
        "\n",
        "model_module = DonutModelPLModule(config, processor, model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-07T20:24:42.230591Z",
          "iopub.status.busy": "2024-04-07T20:24:42.230056Z",
          "iopub.status.idle": "2024-04-08T03:00:07.319597Z",
          "shell.execute_reply": "2024-04-08T03:00:07.318234Z",
          "shell.execute_reply.started": "2024-04-07T20:24:42.230531Z"
        },
        "id": "DuGatm4joLKg",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "from pytorch_lightning.loggers import WandbLogger\n",
        "from pytorch_lightning.callbacks import Callback, EarlyStopping\n",
        "\n",
        "wandb_logger = WandbLogger(project=\"Donut-finetune\", name=\"4forms-epoch-1to3\")\n",
        "\n",
        "class PushToHubCallback(Callback):\n",
        "    def on_train_epoch_end(self, trainer, pl_module):\n",
        "        print(f\"Pushing model to the hub, epoch {trainer.current_epoch}\")\n",
        "        pl_module.model.push_to_hub(\"Henge-navuuu/donut-base-finetuned-forms-v1\",\n",
        "                                    commit_message=f\"Training in progress, epoch {trainer.current_epoch}\")\n",
        "\n",
        "    def on_train_end(self, trainer, pl_module):\n",
        "        print(f\"Pushing model to the hub after training\")\n",
        "        pl_module.processor.push_to_hub(\"Henge-navuuu/donut-base-finetuned-forms-v1\",\n",
        "                                    commit_message=f\"Training done\")\n",
        "        pl_module.model.push_to_hub(\"Henge-navuuu/donut-base-finetuned-forms-v1\",\n",
        "                                    commit_message=f\"Training done\")\n",
        "\n",
        "early_stop_callback = EarlyStopping(monitor=\"val_edit_distance\", patience=3, verbose=False, mode=\"min\")\n",
        "\n",
        "trainer = pl.Trainer(\n",
        "        accelerator='gpu',\n",
        "        devices=1,\n",
        "        max_epochs=config.get(\"max_epochs\"),\n",
        "        val_check_interval=config.get(\"val_check_interval\"),\n",
        "        check_val_every_n_epoch=config.get(\"check_val_every_n_epoch\"),\n",
        "        gradient_clip_val=config.get(\"gradient_clip_val\"),\n",
        "        precision=16, # we'll use mixed precision\n",
        "        num_sanity_val_steps=0,\n",
        "        logger=wandb_logger,\n",
        "        callbacks=[PushToHubCallback(), early_stop_callback],\n",
        ")\n",
        "\n",
        "trainer.fit(model_module)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-08T03:46:45.156584Z",
          "iopub.status.busy": "2024-04-08T03:46:45.155658Z",
          "iopub.status.idle": "2024-04-08T03:47:06.189988Z",
          "shell.execute_reply": "2024-04-08T03:47:06.188887Z",
          "shell.execute_reply.started": "2024-04-08T03:46:45.156543Z"
        },
        "id": "o-LPBIskoLKg",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "from transformers import DonutProcessor, VisionEncoderDecoderModel\n",
        "\n",
        "processor = DonutProcessor.from_pretrained(\"Henge-navuuu/donut-base-finetuned-forms-v1\")\n",
        "model = VisionEncoderDecoderModel.from_pretrained(\"Henge-navuuu/donut-base-finetuned-forms-v1\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-08T03:47:11.111668Z",
          "iopub.status.busy": "2024-04-08T03:47:11.1109Z",
          "iopub.status.idle": "2024-04-08T03:47:27.603554Z",
          "shell.execute_reply": "2024-04-08T03:47:27.602254Z",
          "shell.execute_reply.started": "2024-04-08T03:47:11.111636Z"
        },
        "id": "gzVrAK13oLKg",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "%pip install -q donut-python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_kg_hide-output": true,
        "execution": {
          "iopub.execute_input": "2024-04-08T04:31:51.707714Z",
          "iopub.status.busy": "2024-04-08T04:31:51.707253Z",
          "iopub.status.idle": "2024-04-08T04:31:53.935082Z",
          "shell.execute_reply": "2024-04-08T04:31:53.933521Z",
          "shell.execute_reply.started": "2024-04-08T04:31:51.707679Z"
        },
        "id": "mzEpNGSgoLKg",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import json\n",
        "import torch\n",
        "from tqdm.auto import tqdm\n",
        "import numpy as np\n",
        "\n",
        "from donut import JSONParseEvaluator\n",
        "\n",
        "from datasets import load_dataset\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "model.eval()\n",
        "model.to(torch.device(1))\n",
        "\n",
        "# wandb_logger = WandbLogger(project=\"Donut-finetune\", name=\"4forms-epoch-1to3\")\n",
        "\n",
        "output_list = []\n",
        "accs = []\n",
        "\n",
        "dataset = load_dataset(\"Henge-navuuu/Multiple_financial_forms\", split=\"test\", use_auth_token=True)\n",
        "\n",
        "for idx, sample in tqdm(enumerate(dataset), total=len(dataset)):\n",
        "    # prepare encoder inputs\n",
        "    pixel_values = processor(sample[\"image\"].convert(\"RGB\"), return_tensors=\"pt\").pixel_values\n",
        "    pixel_values = pixel_values.to(torch.device(1))\n",
        "    # prepare decoder inputs\n",
        "\n",
        "    prompt = \"<s>\"\n",
        "    decoder_input_ids = processor.tokenizer(prompt, add_special_tokens=False, return_tensors=\"pt\").input_ids\n",
        "    decoder_input_ids = decoder_input_ids.to(torch.device(1))\n",
        "    print(decoder_input_ids)\n",
        "    # autoregressively generate sequence\n",
        "    outputs = model.generate(\n",
        "            pixel_values,\n",
        "            decoder_input_ids=decoder_input_ids,\n",
        "            max_length=1000,\n",
        "            early_stopping=True,\n",
        "            pad_token_id=processor.tokenizer.pad_token_id,\n",
        "            eos_token_id=processor.tokenizer.eos_token_id,\n",
        "            use_cache=True,\n",
        "            num_beams=1,\n",
        "            bad_words_ids=[[processor.tokenizer.unk_token_id]],\n",
        "            return_dict_in_generate=True,\n",
        "        )\n",
        "\n",
        "    # turn into JSON\n",
        "    seq = processor.batch_decode(outputs.sequences)[0]\n",
        "    seq = seq.replace(processor.tokenizer.eos_token, \"\").replace(processor.tokenizer.pad_token, \"\")\n",
        "    seq = re.sub(r\"<.*?>\", \"\", seq, count=1).strip()  # remove first task start token\n",
        "    seq = processor.token2json(seq)\n",
        "\n",
        "    ground_truth = json.loads(sample[\"ground_truth\"])\n",
        "    ground_truth = ground_truth[\"gt_parse\"]\n",
        "    evaluator = JSONParseEvaluator()\n",
        "    score = evaluator.cal_acc(seq, ground_truth)\n",
        "\n",
        "    accs.append(score)\n",
        "    output_list.append(seq)\n",
        "\n",
        "scores = {\"accuracies\": accs, \"mean_accuracy\": np.mean(accs)}\n",
        "print(scores, f\"length : {len(accs)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HLM9XK_KoLKh"
      },
      "outputs": [],
      "source": [
        "from transformers import DonutProcessor, VisionEncoderDecoderModel\n",
        "\n",
        "processor = DonutProcessor.from_pretrained(\"Henge-navuuu/donut-base-finetuned-1099-div\")\n",
        "model = VisionEncoderDecoderModel.from_pretrained(\"Henge-navuuu/donut-base-finetuned-1099-div\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x1xVra7aoLKh"
      },
      "outputs": [],
      "source": [
        "def process_document(image):\n",
        "    # prepare encoder inputs\n",
        "    pixel_values = processor(image, return_tensors=\"pt\").pixel_values\n",
        "\n",
        "    print(type(pixel_values),pixel_values.shape)\n",
        "\n",
        "    # prepare decoder inputs\n",
        "    task_prompt = \"<s>\"\n",
        "    decoder_input_ids = processor.tokenizer(task_prompt, add_special_tokens=False, return_tensors=\"pt\").input_ids\n",
        "\n",
        "    # generate answer\n",
        "    outputs = model.generate(\n",
        "        pixel_values.to(torch.device(1)),\n",
        "        decoder_input_ids=decoder_input_ids.to(device),\n",
        "        max_length=model.decoder.config.max_position_embeddings,\n",
        "        early_stopping=True,\n",
        "        pad_token_id=processor.tokenizer.pad_token_id,\n",
        "        eos_token_id=processor.tokenizer.eos_token_id,\n",
        "        use_cache=True,\n",
        "        num_beams=1,\n",
        "        bad_words_ids=[[processor.tokenizer.unk_token_id]],\n",
        "        return_dict_in_generate=True,\n",
        "    )\n",
        "\n",
        "    # postprocess\n",
        "    sequence = processor.batch_decode(outputs.sequences)[0]\n",
        "    sequence = sequence.replace(processor.tokenizer.eos_token, \"\").replace(processor.tokenizer.pad_token, \"\")\n",
        "    sequence = re.sub(r\"<.*?>\", \"\", sequence, count=1).strip()  # remove first task start token\n",
        "\n",
        "    return processor.token2json(sequence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UU54z4vxoLKh"
      },
      "outputs": [],
      "source": [
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ipaqPbU7oLKi"
      },
      "outputs": [],
      "source": [
        "image = dataset[20]['image']\n",
        "image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IMl7bFO9oLKi"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "finetuning_for_4_forms",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [],
      "dockerImageVersionId": 30674,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
